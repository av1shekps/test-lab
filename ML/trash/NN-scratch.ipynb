{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing the required Libraries and Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "hCncKe1pCex8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mlxtend.data import loadlocal_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "c8KEwVCvbldd"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining Sigmoid ,Sigmoid Derivative and Loss functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "isyJivEdCwG_"
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "  return 1/(1+np.exp(-x))\n",
    "def sigmoid_derivative(x):\n",
    "  return x*(1-x)\n",
    "\n",
    "def loss(predicted_output,desired_output):\n",
    "  return (desired_output-predicted_output)**2/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing the Required Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "D6mOnQhZcgkL"
   },
   "outputs": [],
   "source": [
    "features, labels = fetch_openml('mnist_784', version=1, return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "HheTC09oc0pc"
   },
   "outputs": [],
   "source": [
    "features = (features/255).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "58_e0aecc4cf"
   },
   "outputs": [],
   "source": [
    "labels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dividing data into train and test datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-XkNp8rDc8hA",
    "outputId": "71e1a4b4-d80b-46ba-d2ec-d714fd00b7d0"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(features, labels, test_size=0.15, random_state=37)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building the Neural Network from the scratch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "3MiMPGMqDHl7"
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "  def __init__(self,inputLayerNeuronNumber,hiddenLayerNeuronNumber,outputLayerNeuronNumber):\n",
    "    self.inputLayerNeuronNumber=inputLayerNeuronNumber\n",
    "    self.hiddenLayerNeuronNumber=hiddenLayerNeuronNumber\n",
    "    self.outputLayerNeuronNumber=outputLayerNeuronNumber\n",
    "\n",
    "    self.hidden_weights=np.random.randn(self.hiddenLayerNeuronNumber,self.inputLayerNeuronNumber)*np.sqrt(2/inputLayerNeuronNumber)  #generating random hidden weights from input to hidden layer\n",
    "    self.hidden_bias=np.zeros([self.hiddenLayerNeuronNumber,1])        #zero bias weights for the hidden layer\n",
    "\n",
    "    self.output_weights=np.random.randn(self.outputLayerNeuronNumber,self.hiddenLayerNeuronNumber)  #generating random output weights from hidden layer to the output layer\n",
    "    self.output_bias=np.zeros([self.outputLayerNeuronNumber,1])    #zero bias for the output layer\n",
    "    self.loss=[]\n",
    "    self.learning_rate=0.1   #learning rate \n",
    "\n",
    "  def train(self,input,desired_output):\n",
    "\n",
    "    self.hidden_layer_in=np.dot(self.hidden_weights,input)+self.hidden_bias     #Forward propagation to calculate output values\n",
    "    self.hidden_layer_out=sigmoid(self.hidden_layer_in)\n",
    "\n",
    "    self.output_layer_in=np.dot(self.output_weights,self.hidden_layer_out)+self.output_bias\n",
    "    self.predicted_output=sigmoid(self.output_layer_in)\n",
    "\n",
    "    self.output_error=desired_output-self.predicted_output                 #Backward propagation to calculate errors\n",
    "    self.d_output_error=self.output_error*(sigmoid_derivative(self.predicted_output))\n",
    "\n",
    "    self.hidden_layer_error=self.d_output_error.T.dot(self.output_weights)\n",
    "    self.d_hidden_layer_error=self.hidden_layer_error.T*sigmoid_derivative(self.hidden_layer_out)\n",
    "\n",
    "    self.output_weights+=self.hidden_layer_out.dot(self.d_output_error.T).T*self.learning_rate\n",
    "    self.output_bias+=np.sum(self.d_output_error,axis=1,keepdims=True)*self.learning_rate\n",
    "\n",
    "    self.hidden_weights+=input.dot(self.d_hidden_layer_error.T).T*self.learning_rate       #Updating weights \n",
    "    self.hidden_bias+=np.sum(self.d_hidden_layer_error,axis=1,keepdims=True)*self.learning_rate\n",
    "    self.loss.append(loss(desired_output,self.predicted_output))\n",
    "\n",
    "  def predict(self, inputs):\n",
    "      hidden_layer_in = np.dot(self.hidden_weights, inputs) + self.hidden_bias   #Forward propagation on test dataset\n",
    "      hidden_layer_out = sigmoid(hidden_layer_in)\n",
    "      output_layer_in = np.dot(self.output_weights, hidden_layer_out) + self.output_bias\n",
    "      predicted_output = sigmoid(output_layer_in)\n",
    "      return predicted_output\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Running the Neural Network model for the Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F2mlQ94tDzHk",
    "outputId": "2092e2d5-054d-4477-cba8-27bb1bb47e51"
   },
   "outputs": [],
   "source": [
    "nn=NeuralNetwork(784,350,10)   #creating Neural Network with 784 input nodes ,350 hidden nodes and 10 output nodes\n",
    "X_train=np.array(X_train)\n",
    "Y_train=np.array(Y_train)\n",
    "for i in range(X_train.shape[0]):          #Stochastic weight update\n",
    "    inputs = np.array(X_train[i, :])\n",
    "    inputs=inputs.reshape(-1,1)\n",
    "    desired_output = np.array(Y_train[i, :])\n",
    "    desired_output=desired_output.reshape(np.shape(desired_output)[0],1)\n",
    "    \n",
    "    nn.train(inputs, desired_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predicting the output for the test dataset and calculating accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qbKz0sdFdWj7",
    "outputId": "5d00aae5-b752-45fe-83f1-9e571a0e08d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is :  75.81904761904762  %\n"
     ]
    }
   ],
   "source": [
    "prediction_list = []\n",
    "prediction_list.append(nn.predict(X_test.T))\n",
    "prediction_list=np.array(prediction_list)\n",
    "prediction_list=prediction_list.T\n",
    "correct_counter = 0\n",
    "for i in range(len(prediction_list)):\n",
    "    out_index = np.where(prediction_list[i] == np.amax(prediction_list[i]))[0][0]\n",
    "    \n",
    "    if Y_test[i][out_index] == 1:\n",
    "        correct_counter+=1\n",
    "\n",
    "accuracy = correct_counter/10500\n",
    "\n",
    "print(\"Accuracy is : \",accuracy*100,\" %\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
